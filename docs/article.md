OpenAI released their API for the O1 model, so I wanted to try it out just to see what we can do with it I'm probably gonna run this in cursor because I don't have access yet Even though I am on tier 5 a bit strange, but I probably they are just rolling it out over time, I guess yeah, I don't have it here, but The reason I saw this is that on live bench now You can see O1 this version is on top for coding So I wanted to give it a spin here on cursor just to do a few examples To see what we can write about it. Check out the latency. Will this replace my cloud 3.5? I doubt it, but let's see now what we can do with this So I think we're gonna start by just making a Simple thing with real-time API with the web RTC. That was also something new from OpenAI So I think we're just gonna copy this documentation here Just head over to cursor. I Made a file here. So I'm just gonna paste in this documentation Then I think we're just gonna open up the chat, right? I selected the O1 model here in Cursor if you want to try this yourself You have to set like a hard limit because yeah something about you have to pay for it or something But I'm gonna test it out now just to see what we can do with it So I think we're gonna do like a one-shot prompt here to try to build this web RTC Small application to see what we can do with this. So let's do the prompt I want to build a simple web app RT voice dot HTML where the user can input the API key start talking with the real-time API I also want a drop-down menu that selects between the voice Ballad and verse let's also display a connection monitoring established not connected and a start stop button So I select O1 and let's do yeah Enter I guess so let's monitor the latency now because that is what I'm most worried about That this is gonna take a very long time each time you want to do something small So yeah already I can kind of feel that this is slower than Claude 3.5 And that is something I don't want to do. I guess I could use O1 in some cases Okay, I guess it didn't stream. So we came back with a result here So let's apply this But if this works first time I guess it does that isn't too bad I thought we maybe needed a server for this, but let's try it out So I'm just gonna open up This I do like a Python so we can serve this on port 8,000 Maybe I should have said that but let's try that now. Let's go to this port here and let's open up this Okay So far is looking pretty good. So we have the drop-down. That's good. We have the start we are they're not connected So I'm gonna grab an API key here to see if this works, so let's paste in our key and click start Hello Hello, hello. Hey there. Hello again. What's on your mind today? Not much. How are you? I'm just a bundle of digital energy always. Okay, so let's stop it. Let's try to switch up the voice Hello Hello there, how's it going? I'm good. What about you? I'm doing great. Thanks for asking. Okay, that was pretty good, right? That was a one-shot prompt We got the code straight away. We got everything we needed that so that was a bit better than I thought So I was kind of impressed by this so we could build this out now So let's try to improve the UI a bit. Give it a more like let's go for like a retro terminal feel So let's go back to cursor and let's do a new prompt here just to follow up on this So let's follow up with great that work now. I want to style the UI I want a super retro minimalistic terminal UI black and white some well-known terminal animations maybe a hint of dark green make it stylish and very Nostalgic feeling so again, let's try the or one prompting here. So hopefully now we're just gonna edit our HTML here again, I expect this is gonna take a bit of a time But it wasn't too bad. Like I think this entry was a big improvement if we compare it to or one preview and That is kind of one of their sales point. Yeah, that wasn't too bad. How long is that maybe around 10 20 seconds? Okay, so we got So let's just implement this here. Okay, so let's go back here All right, that is something right? Not too bad. We have some simple animations here. Let's try to just I want to give it like more freedom. So let's do Okay, good, let's just do make it more terminal based. Let's start green put all the content into an interactive terminal window So again, we're gonna try to see what this does Okay, so let's apply this say that it's refresh Yeah, this is more what I was looking for So I'm pretty happy with this. So let me paste in the key again. Let's select this start and Hello Hey there, how's it going? What can I do for you today? Switch up the voice Hello Hello Hey there. How's it going? Yeah, the voice switching was pretty good. So I'm pretty happy. I don't really like this part though It's a bit strange. Let's try to remove that. So let's just do let's remove the pop-up play volume controls Hopefully this shouldn't take too long. So let's just stay here now to check the latency So, yeah, it's been like five seconds, I guess we still have these reasoning tokens So it will be slower naturally because it has to go through this step by step instruction list, right? So, yeah, not too bad But again, I could have implemented streaming. So let's refresh this now. Let's try again Hello Hello there, okay. Yeah perfect. So so far I gotta say it worked pretty good How long did that take me around maybe 10 minutes to set everything up? I think I want to do one more thing because testing out this model in Just a few a short video. It's not gonna cut it but at least I get some impression now what I think and this Solution we have here by one shotting this web RTC integration of the real-time API worked out pretty good So I think I'm gonna start one more project and let's see if we can one shot that So I'm gonna fire up something new gather some documentation and let's try it Okay, so I decided what I want to do. I want to implement structured outputs. I want to implement whisper and Some other stuff so we can kind of record our conversation into maybe like an mp3 file We can translate that using whisper and then we can use structured outputs and maybe like a GPT for Oh call To try to extract some data from our conversation with the real-time API. So I'm just gonna gather some Data here. So I'm not they added this copy page. I like that so I can copy this Let's go back to our documentation here 1100 lines, so let's grab speech to text. So this is gonna be whisper. I Think so. Let's copy that information paste that into the docks Another 500 lines. Is there anything else made and guess we need text generation. So let's do that Okay, so we got about 2,000 lines of documentation now And I think we're gonna include We're gonna include the RT voice here in this Context let's do a dot ENV and let's do an open a Let's do an open AI API key input here Let's add this So let me come up with a one-shot prompt for all of the project now If all one can do this in one shot I'm gonna be pretty impressed my one-shot prompt for this is gonna be I want to build on the RT voice HTML project This runs the real-time API and is a conversation between the user and the API We want to extract some data from the conversation for the next step of this project It will work as follows The user and the API has a conversation the conversation must be recorded as a temporary mp3 file We can run in whisper to transcribe this into text in a JSON format Then we have the transcript you want to use the GPT 4 o API and structured outputs to extract data Into a JSON format the data we want is sentiment topic conversation and any dates from the conversation Extracted data must be saved into a data JSON in the CVD. Look at the documentation write all the code We need to implement this into our project So if this works on the one shot, I will be very surprised but let's try it now, so just gonna press enter It's a long file. So this is probably gonna take some time, but I'll come back when we have this
this. And I just give like a quick report how long this took. Okay, so we have the response. So this took about, I will say 40 seconds, 30, 45, 50 seconds around that. So we have a new code here for this RT voice. So let's implement this. Okay, interesting. And if we scroll down, we need to create our server dot j s, we just can apply this right away. Great. We save that. We have some installations we have to do. So let me open up the terminal. So we're going to install some dependencies here. We want to export our open AI key. So I'm going to do that. Okay, so I set my API key. Now we can run the server. And then let's head over here. So now we are in our HTML, right? So I'm going to paste in API key. I'm going to try start. Let's open up the console to Hello. Hey there, what can I do for you today? I just need the date. That's about it. Today's date is December 19 2024. Anything else you need? I think that's it. So thank you very much. I enjoyed your service. Let's speak soon. You're welcome. I'm glad I could help. Don't hesitate to reach out if you need and hello again. Bye. What's on? Goodbye. Have a Okay, so I clicked Stop now. Okay, so we have an error here. I guess you can see it. It's in the console here. So let me grab this error. There's something about the course policy. So I'm going to copy this. So it didn't work one shot. But let's see how quick we can fix this. Now. Let's do Okay, I get this console error. Let's paste in that. Can you fix it is a pretty ambitious thing to one shot. So I was expecting we had to do some iterations. So let's see how quickly we can fix this now if it's even possible. Okay, so I went a bit back and forward not big changes. So let's try this now. So let's copy this new RT voice here. So we added about 50 lines of code here. Let's update the server code. Let's go to our server. Let's apply this. Okay, let's say that I think we got it now. So this is pretty impressive. Let's run our node server now. And let's head over to let's head back here and let's refresh our localhost. So paste in our key. So the idea now is that when we talk, we can you have a conversation, we can actually Yeah, we want to mention a date, I think. And the idea is that we can record all of this and extract the data. So we have that using structured outputs, right? Hello. Hello there. How's it going? I'm pretty good. I have a bit of a conundrum. I don't know the date for today. And I also need to know how many days it is to Christmas Eve because I got some present I need to buy. Today is December 19. So Christmas Eve is just five days away. You still have some time to get those presents. But it's sneaking up fast. Yeah, that's true. Well, thank you for that. And is there anything else you want to say before I leave? Just that I hope you have a fantastic time shopping for those gifts and enjoy the holiday season. Thank you. Bye. Bye. Have a great day. Okay, so when we stop this now, you can see we should get like a pop up or like a toast or something here. Yeah. Conversation process check the logs for structured data. So if we go here now, you can see you can we have the transcription from our conversation, we have the assistance from the real time events. And we have what we said that was kind of recorded. Then we can use structured outputs to put this into a JSON file. Perfect. So we have the sentiment positive Christmas Eve and buying present that was the topic and we extracted December 19. Perfect. So you can see that work pretty good. I guess my conclusion is that it was pretty impressive. We didn't one shot this, but this is quite the task to do. And I've been trying this, not this exact setup, but using this HTML file to try to record something before. It's not that easy to do with Claude. So, so far, I'm pretty impressed by 01. Will I switch to 01 to make it like my main model? I'm not sure. But I'm certainly going to use it like if I'm stuck on 3.5, I might switch to 01. But I need more time to kind of, yeah, evaluate what model I will be using in cursor going forward. But I'm pretty sure already that I will be switching between the two. I only miss streaming from 01. I just like watching when Claude 3.5 streams. But other than that, I think this was a very good test for me. I'm pretty positive on going forward, trying out a bit more 01 in cursor. So yeah, hope you enjoyed it. Hope all get access to the 01 API soon so we can start doing even more testing to find out what we like the most and what's going to bring us the best results